---
layout: post
title: "[DE][독서] 01. 빅데이터를 지탱하는 기술"
subtitle: "제목: '빅데이터를 지탱하는 기술', 저자: '니시다 케이스케', 출판사: '제이펍'"
date: 2021-04-10 10:45:13
background: '/img/posts/CS_01_프로그래밍사진.jpg'
categories: ['Data Engineering','Reading Record']
---

<blockquote class="blockquote"></blockquote>
<h2 class="section-heading">빅데이터를 지탱하는 기술</h2>

<h4>책 소개</h4>
<p>데이터 처리를 어떻게 시스템화하는지 설명하는 책이다. 데이터 처리 과정에 사용되는 SW, 데이터베이스, 프로그래밍 언어와 시각화 도구 등 특징을 잘 정리했다. 효율적 데이터 처리 방법론, 워크플로 관리, 스트림 처리 등 데이터 처리의 자동화 기술을 소개해주는 저서다.</p>

<h4>저자 및 출판사</h4>
<ul>
    <li><strong>저자</strong>: 니시다 케이스케</li>
    <li><strong>출판사</strong>: 제이펍</li>
    <li><strong>독서일자</strong>: 21.03 - 21.04</li>
</ul>>

&nbsp;

&nbsp;

<h3 class="section-heading">1. 빅데이터의 기초 지식</h3>

<h4>데이터 파이프라인이란?</h4>

<p>차례대로 전달해나가는 데이터로 구성된 시스템. 데이터 수집에서 워크플로 관리까지 일반적으로 일컫음</p>
<p><strong>핵심은, 데이터 처리 자동화와 장기적 운용을 위해서는 안정된 워크플로 관리가 필수적이라는 것임</strong></p>

<p><strong>데이터 파이프라인의 일반적 구조: </strong>데이터 수집 -> (스트림 처리) -> 분산 스토리지 -> 분산 데이터 처리 -> 데이터 마트 or 시계열 DB</p>


<h4>파이프라인 구조 살펴보기</h4>

<h4>1. 데이터 수집을 위한 전송</h4>

<ul>
    <li><strong>벌크형</strong>기존에 있는 데이터를 정리해 추출. 정기적으로 데이터 수집 시 사용, 데이터 수집자료는 분산 스토리지로 전달</li>
    <li><strong>스트리밍형</strong>차례대로 생성되는 데이터를 계속해서 보내는 방법. *스트림 처리 후 분산 스토리지로 전달</li>
</ul>>

<h4>2. 스트림 처리</h4>
<p>스트림 처리란? 실시간 데이터를 처리하는 방법. 모바일 앱 증가하며 중요성 증가됨. 그러나, '엄청난 양의 데이터를 처리'하므로 장기적 데이터 분석에는 적합하지 않음.</p>

<p>스트림 처리의 단점을 보완하기 위해, <strong>배치처리 구조</strong>를 사용함. 이는 대량의 데이터를 저장하고 처리하는 분산 시스템을 의미.</p>

<p>Q질문: 배치처리란? 찾아보기!</p>

<h4>3. 분산 스토리지</h4>
<p>여러 컴퓨터와 디스크로부터 구성된 스토리지 시스템. 대표적으로는 <strong>객체 스토리지</strong>(한 덩어리로 모인 데이터에 이름 부여해 파일로 저장하는 방법)이 있음. 객체 스토리지의 대표적 예시로는 Amazon S3.</p>
<p>NoSQL을 분산 스토리지로 사용할 수 있지만 나중에 데이터 용량을 얼마든지 늘릴 수 있는 확장성 높은 제품을 선택하는 것이 좋음.</p>

<h4>4. 분산 데이터 처리</h4>
<p>나중에 분석하기 쉽도록 데이터를 가공해서 외부 DB에 저장하는 것. 대표적인 예로 MapReduce가 있음. 요즘은 분산 스토리지 자체에서 데이터를 SQL로 집계할 수 있는 쿼리엔진(예:Hive,대화형 쿼리엔진)이 있음</p>

<p>혹은 앞서 언급한대로 외부 DB에 저장하기도 하는데, 분산 스토리지 데이터를 DW에 적합한 형식으로 변환. 이 절차를 <strong>ETL 프로세스</strong>라고 일컫음</p>

<p><strong>ETL프로세스</strong>: 스토리지(소스)에서 데이터를 추출, 가공, DW에 로드하는 절차</p>
<p><strong>ELT프로세스</strong>: 스토리지(소스)에서 데이터를 추출, DW에 로드 후 데이터를 가공</p>
<p>Q질문: 스토리지와 데이터 소스는 같은 개념인가? 스토리지가 없이 바로 소스에서 추출가공할 수도 있는가?</p>

<h4>데이터 웨어하우스와 데이터 마트</h4>
<p><strong>데이터 소스</strong>: 테이블/RDB/로그 등 원시 데이터를 저장하는 파일 서버</p>
<p><strong>데이터 웨어하우스</strong>: ETL 거쳐 장기 보존용 데이터로 정리한 테이블</p>
<p><strong>데이터 마트</strong>: ETL 거쳐 필요한 데이터만을 추출해 BI 도구와 결합하는 등 시각화 및 분석에 이용.</p>
<p>데이터 마트를 생성하는 이유: 웨어하우스 내에서 분석을 거치면 시스템 과부하 초래 우려, 오류 발생 시 데이터 유실 및 이슈 발생 방지</p>

<h4>데이터 레이크</h4>
<p>여러 곳에서 데이터가 흘러 들어오는 호수. 일반적으로는 분산 스토리지가 데이터레이크로써 이용됨. 데이터 레이크가 데이터 웨어하우스로 치환되기도 하는데, 이 경우에는 데이터레이크 -> 데이터마트로 파이프라인이 구성됨.</p>
<p>데이터레이크는 단순한 스토리지어서, MapReduce를 활용해 분석에 필요한 데이터를 가공,집계하여 마트로 추출</p>

&nbsp;

<h4>데이터 프로젝트의 시작</h4>
<p>처음 프로젝트를 시작할 시, 수작업으로 데이터를 집계하는데 이것을 애드혹 분석이라고 함. 이 때는 데이터 마트를 만들지 않은 채 데이터 레이크 or 웨어하우스와 직접 연결하는 경우가 많음.</p>
<p>대시보드: 데이터 마트가 없어도 동작하도록 설계되어 있고, 일정 스케줄마다 데이터 웨어하우스에서 쿼리를 실행해 시각화</p>
<p>복잡한 데이터의 경우에는 마트를 구성하기도 함. 시각화에 BI도구 사용할 때에는, <strong>집계 속도 향상을 위해 마트를 필수적으로 구성</strong></p>

<h4>데이터를 수집하는 목적</h4>
<p><strong>데이터 검색</strong></p>
<p>데이터 오류 등이 났을 때 확인하기 위해, 분산 스토리지에서 실시간으로 데이터 처리 or 검색엔진을 사용할 수 있도록 해야 함</p>
<p><strong>데이터 가공</strong></p>
<p>분산 스토리지에서 배치처리 등으로 데이터가 가공되는 것. 이는 자동화가 필수적임. 워크플로 관리를 도입해 테스트 반복적으로 실행해가며 꼼꼼하게 시스템 구축해야 함</p>
<p><strong>데이터 시각화</strong></p>
<p>시각화 고속화를 위해서는 데이터 마트를 염두에 두어야 함. 변화 감시 도구의 일종</p>

<h3 class="section-heading">2. 빅데이터의 탐색</h3>

<h4>테이블의 종류</h4> <!--여기서부터 시작하자 45페이지부터!-->
<ul>
    <li><strong>벌크형</strong>기존에 있는 데이터를 정리해 추출. 정기적으로 데이터 수집 시 사용, 데이터 수집자료는 분산 스토리지로 전달</li>
    <li><strong>스트리밍형</strong>차례대로 생성되는 데이터를 계속해서 보내는 방법. *스트림 처리 후 분산 스토리지로 전달</li>
</ul>>
<h3 class="section-heading">3. 빅데이터의 분산 처리</h3>
<h3 class="section-heading">4. 빅데이터의 축적</h3>
<h3 class="section-heading">5. 빅데이터의 파이프라인</h3>
<h3 class="section-heading">6. 빅데이터 분석 기반의 구축</h3>

