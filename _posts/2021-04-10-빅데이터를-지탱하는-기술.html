---
layout: post
title: "[DE][독서] 01. 빅데이터를 지탱하는 기술"
subtitle: "제목: '빅데이터를 지탱하는 기술', 저자: '니시다 케이스케', 출판사: '제이펍'"
date: 2021-04-10 10:45:13
background: '/img/posts/CS_01_프로그래밍사진.jpg'
categories: ['Data Engineering','Reading Record']
---

<blockquote class="blockquote"></blockquote>
<h2 class="section-heading">빅데이터를 지탱하는 기술</h2>

<h4>책 소개</h4>
<p>데이터 처리를 어떻게 시스템화하는지 설명하는 책이다. 데이터 처리 과정에 사용되는 SW, 데이터베이스, 프로그래밍 언어와 시각화 도구 등 특징을 잘 정리했다. 효율적 데이터 처리 방법론, 워크플로 관리, 스트림 처리 등 데이터 처리의 자동화 기술을 소개해주는 저서다.</p>

<h4>저자 및 출판사</h4>
<ul>
    <li><strong>저자</strong>: 니시다 케이스케</li>
    <li><strong>출판사</strong>: 제이펍</li>
    <li><strong>독서일자</strong>: 21.03 - 21.04</li>
</ul>>

&nbsp;

&nbsp;

<h3 class="section-heading">1. 빅데이터의 기초 지식</h3>

<h4>데이터 파이프라인이란?</h4>

<p>차례대로 전달해나가는 데이터로 구성된 시스템. 데이터 수집에서 워크플로 관리까지 일반적으로 일컫음</p>
<p><strong>핵심은, 데이터 처리 자동화와 장기적 운용을 위해서는 안정된 워크플로 관리가 필수적이라는 것임</strong></p>

<p><strong>데이터 파이프라인의 일반적 구조: </strong>데이터 수집 -> (스트림 처리) -> 분산 스토리지 -> 분산 데이터 처리 -> 데이터 마트 or 시계열 DB</p>


<h4>파이프라인 구조 살펴보기</h4>

<h4>1. 데이터 수집을 위한 전송</h4>

<ul>
    <li><strong>벌크형</strong>기존에 있는 데이터를 정리해 추출. 정기적으로 데이터 수집 시 사용, 데이터 수집자료는 분산 스토리지로 전달</li>
    <li><strong>스트리밍형</strong>차례대로 생성되는 데이터를 계속해서 보내는 방법. *스트림 처리 후 분산 스토리지로 전달</li>
</ul>>

<h4>2. 스트림 처리</h4>
<p>스트림 처리란? 실시간 데이터를 처리하는 방법. 모바일 앱 증가하며 중요성 증가됨. 그러나, '엄청난 양의 데이터를 처리'하므로 장기적 데이터 분석에는 적합하지 않음.</p>

<p>스트림 처리의 단점을 보완하기 위해, <strong>배치처리 구조</strong>를 사용함. 이는 대량의 데이터를 저장하고 처리하는 분산 시스템을 의미.</p>

<p>Q질문: 배치처리란? 찾아보기!</p>

<h4>3. 분산 스토리지</h4>
<p>여러 컴퓨터와 디스크로부터 구성된 스토리지 시스템. 대표적으로는 <strong>객체 스토리지</strong>(한 덩어리로 모인 데이터에 이름 부여해 파일로 저장하는 방법)이 있음. 객체 스토리지의 대표적 예시로는 Amazon S3.</p>
<p>NoSQL을 분산 스토리지로 사용할 수 있지만 나중에 데이터 용량을 얼마든지 늘릴 수 있는 확장성 높은 제품을 선택하는 것이 좋음.</p>

<h4>4. 분산 데이터 처리</h4>
<p>나중에 분석하기 쉽도록 데이터를 가공해서 외부 DB에 저장하는 것. 대표적인 예로 MapReduce가 있음. 요즘은 분산 스토리지 자체에서 데이터를 SQL로 집계할 수 있는 쿼리엔진(예:Hive,대화형 쿼리엔진)이 있음</p>

<p>혹은 앞서 언급한대로 외부 DB에 저장하기도 하는데, 분산 스토리지 데이터를 DW에 적합한 형식으로 변환. 이 절차를 <strong>ETL 프로세스</strong>라고 일컫음</p>

<p><strong>ETL프로세스</strong>: 스토리지(소스)에서 데이터를 추출, 가공, DW에 로드하는 절차</p>
<p><strong>ELT프로세스</strong>: 스토리지(소스)에서 데이터를 추출, DW에 로드 후 데이터를 가공</p>
<p>Q질문: 스토리지와 데이터 소스는 같은 개념인가? 스토리지가 없이 바로 소스에서 추출가공할 수도 있는가?</p>

<h4>데이터 웨어하우스와 데이터 마트</h4>
<p><strong>데이터 소스</strong>: 테이블/RDB/로그 등 원시 데이터를 저장하는 파일 서버</p>
<p><strong>데이터 웨어하우스</strong>: ETL 거쳐 장기 보존용 데이터로 정리한 테이블</p>
<p><strong>데이터 마트</strong>: ETL 거쳐 필요한 데이터만을 추출해 BI 도구와 결합하는 등 시각화 및 분석에 이용.</p>
<p>데이터 마트를 생성하는 이유: 웨어하우스 내에서 분석을 거치면 시스템 과부하 초래 우려, 오류 발생 시 데이터 유실 및 이슈 발생 방지</p>

<h4>데이터 레이크</h4>
<p>여러 곳에서 데이터가 흘러 들어오는 호수. 일반적으로는 분산 스토리지가 데이터레이크로써 이용됨. 데이터 레이크가 데이터 웨어하우스로 치환되기도 하는데, 이 경우에는 데이터레이크 -> 데이터마트로 파이프라인이 구성됨.</p>
<p>데이터레이크는 단순한 스토리지어서, MapReduce를 활용해 분석에 필요한 데이터를 가공,집계하여 마트로 추출</p>

&nbsp;

<h4>데이터 프로젝트의 시작</h4>
<p>처음 프로젝트를 시작할 시, 수작업으로 데이터를 집계하는데 이것을 애드혹 분석이라고 함. 이 때는 데이터 마트를 만들지 않은 채 데이터 레이크 or 웨어하우스와 직접 연결하는 경우가 많음.</p>
<p>대시보드: 데이터 마트가 없어도 동작하도록 설계되어 있고, 일정 스케줄마다 데이터 웨어하우스에서 쿼리를 실행해 시각화</p>
<p>복잡한 데이터의 경우에는 마트를 구성하기도 함. 시각화에 BI도구 사용할 때에는, <strong>집계 속도 향상을 위해 마트를 필수적으로 구성</strong></p>

<h4>데이터를 수집하는 목적</h4>
<p><strong>데이터 검색</strong></p>
<p>데이터 오류 등이 났을 때 확인하기 위해, 분산 스토리지에서 실시간으로 데이터 처리 or 검색엔진을 사용할 수 있도록 해야 함</p>
<p><strong>데이터 가공</strong></p>
<p>분산 스토리지에서 배치처리 등으로 데이터가 가공되는 것. 이는 자동화가 필수적임. 워크플로 관리를 도입해 테스트 반복적으로 실행해가며 꼼꼼하게 시스템 구축해야 함</p>
<p><strong>데이터 시각화</strong></p>
<p>시각화 고속화를 위해서는 데이터 마트를 염두에 두어야 함. 변화 감시 도구의 일종</p>

<h3 class="section-heading">2. 빅데이터의 탐색</h3>

<h4>테이블의 종류</h4> <!--여기서부터 시작하자 45페이지부터!-->
<ul>
    <li><strong>트랜잭션 테이블: </strong>열 추가 방식. 많은 사람들이 엑셀 등으로 보고서 작업 하는 형식이나 데이터 관리 어려움</li>
    <li><strong>크로스 테이블: </strong>행 추가 방식. 아래로 데이터가 쌓이는 방식</li>
    <li><strong>피벗 테이블: </strong>트랜젝션 테이블에서 크로스 테이블로 변환해 생성된 테이블</li>
</ul>>

<h4>마트 크기의 중요성</h4>
<p>마트와 정보전달은 trade off 관계. 마트가 거대화되면 좋은 시각화를 할 수 없고, 마트가 단순하면 다양한 정보전달이 불가능. <br><strong>데이터 마트 크기에 따라 시스템 구성이 결정</strong>됨</p>

<h4>대량 데이터 신속히 집계하기 위한 방법</h4>
<p>적은 양의 데이터: RDB(PostgreSQL, MySQL 등)이 적합, 단 메모리 부족 시 급격한 성능 저하</p>
<p><strong>방법1. 압축과 분산(MPP)</strong>: 데이터를 최대한 작게 압축하고 여러 디스크에 분산.(데이터 로드 지연 줄이기 위함). 데이터를 읽을 땐, 멀티 코어 활용해 디스크 I/O를 병렬처리. (ex:구글 빅쿼리)</p>
<p>MPP는 데이터 집계에 최적화됨. 데이터 웨어하우스와 데이터 분석용의 DB에서 많이 활용됨</p>

<p><strong>방법2. 열지향 데이터베이스 활용</strong></p>>
<p>행지향 데이터베이스: 대량 트랜잭션 지연없이 처리하기 위해 데이터 추가를 행 단위로 효율적으로 하는 루조. 데이터 검색 고도화 위해 index를 사용하며, 일반적 DB가 이에 해당</p>
<p>열지향 데이터베이스: 데이터 분석에 사용되는 DB. 칼럼 단위의 읽고 쓰기 최적화되어 있으며, 필요한 열만을 로드할 수 있고, 매우 작게 압축이 가능(유사한 데이터가 반복되기 때문)하여 디스크 I/O 줄임. Teradata & Amazon Redshift가 이에 해당</p>

<p><strong>MPP 데이터베이스 접근방식 활용</strong><br>MPP란? 하드웨어 수준에서 데이터 집계에 최적화된 DB. MPP아키텍처에 의한 데이터 처리 병렬화를 하면, 쿼리 지연을 줄임.</p>
<p>예시로, 1억 레코드 이뤄진 테이블 합계를 계산하기 위해 10만 레코드로 구분해 1000개 태스크로 나눈 것. 이를 독립적으로 10만 레코드 합계를 집계해 마지막 결과를 모아 산출. 여러 디스크에 분산된 데이터가 서로 다른 CPU코어에서 처리돼 모아짐. 따라서 CPU 코어 수에 비례해 고속화. 단, 병목현상 없도록 데이터 고루 분포해야 함</p>
<p>대화형 쿼리엔진과 MPP DB 중 선택해 사용하는데, 보통 하둡과 대화형 쿼리엔진과의 궁합이 좋은 편이다.</p>
<p>Q질문. 대화형 쿼리엔진이란?</p>

<h4>데이터마트의 기본구조 개념 살펴보기</h4>
<p><strong>OLAP</strong>: 데이터 집계를 효율화하는 접근 방법 중 하나. RDB는 모델링된 데이터를 SQL로 집계하는 한편, OLAP에서는 다차원 모델의 데이터 구조를 MDX등의 쿼리 언어로 집계.</p>
<p><strong>OLAP 큐브</strong>:데이터 분석을 위해 만들어진 다차원 데이터, 이것을 크로스 집계하는 것이 OLAP</p>
<p>테이블 비정규화: 트랜잭션 - 시간과 함께 생성되는 데이터를 기록한 것, 마스터 - 트랜잭션에서 참고되는 각종 정보. 트랜잭션은 한번 기록하면 변화하지 않지만 말스터는 상황에 따라 다시 쓰임. ex)상품마스터 - 상품카테고리 -상품명 - 상품ID</p>
<p>팩트 테이블과 디맨전 테이블</p>
<p>팩트테이블: 트랜젝션.ex:판매액. 디멘전테이블:마스터데이터. 데이터분류 위한 속성값</p>

<p>스타스키마: 팩트테이블 하나에 디멘젼 여러개 붙어있는 형태. 데이터 이해하기 쉽고 단순하며 분석을 쉽게할 수 있다. 또한 팩틑에ㅣ블이 메모리 용량 초과한 시점에서 디스크 I/O발생하며 대기 시간이 쿼리 지연으로 이어지므로, <strong>팩트테이블을 될수 있는 한 작게하는 것이 고속화에서 중요. 하지만 옛날방식.</strong>하다. (데이터 증가시 디맨젼보다 팩트테이블이 훨씬 더 많이 커지므로.)ID 등을 제외한 나머지는 디멘젼으로 넘기는 것이 좋다.</p>
<p>비정규화: 열지향스토리지로 칼럼단위로 데이터가 저장된다. 칼럼 수가 늘어나는 것은 성능에 영향을 주지 않는다. 컬럼 단위로 데이터 압축이 가능해져, 데이터를 디멘젼 테이블로 이동시킬 이유가 없어 하나의 거대한 팩트테이블만 있으면 충분하다. 따라서 데이터 마트는 비정규화 테이블로 만들어도 일정 레코드에서 문제가 없어, 마트의 경우 비정규화 테이블로 만드는 것이 좋다.(플젝마다 차이가 있음)</p>
<h3 class="section-heading">3. 빅데이터의 분산 처리</h3>
<h4>구조화 데이터와 비구조화 데이터</h4>
<p>구조화 데이터: 스키마가 명확히 정의된 데이터, 비구조화 데이터: 자연언어 텍스트 데이터, 이미지, 동영상 등의 미디어 데이터처럼 스키마가 없는 데이터</p>
<p>스키마리스 데이터: 칼럼 수나 데이터형은 명확하지 않으나 데이터의 서식은 있는 것(ex: CSV, JSON, XML). 스키마 지정은 시간이 소요되므로, 데이터 레이크(or분산 스토리지)에 몽땅 넣은 뒤 필요한 데이터만 스키마를 지정하기도 함.(이때 MPP 데이터베이스 or 하둡을 활용해 열지향 스토리지 형식으로 변환)</p>
<h4> HADOOP</h4>
<p>hadoop: 분산 시스템을 구성하는 다수 소프트웨어로 이뤄진 집합체.(hadoop2 yarn...) 즉, 대규모 분산시스템을 구축하기 위한 공통 플랫폼의 역할</p>
<p>구성요소: 분산 파일시스템(HDFS), 리소스 관리자(YARN), 분산 데이터 처리(MapReduce) 등</p>
<p>이 구성요소를 모두 사용하지 않아도, 다른 것들과 결합해 사용할 수 있다.</p>

<p>분산파일시스템(HDFS): 데이터가 저장되는 곳. 다수 컴퓨터에 파일을 복사해 중복성을 높인다는 특징이 있음</p>

<h3 class="section-heading">4. 빅데이터의 축적</h3>
<h3 class="section-heading">5. 빅데이터의 파이프라인</h3>
<h3 class="section-heading">6. 빅데이터 분석 기반의 구축</h3>

