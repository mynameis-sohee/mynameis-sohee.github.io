---
layout: post
title: "[DL] 03. 텍스트마이닝과 NLP 개요"
subtitle: "NLP와 텍스트마이닝 정의 및 절차, 라이브러리 설명"
date: 2021-04-13 10:45:13
background: '/img/posts/DL_01_텍스트마이닝사진.png'
categories: ['Deep Learning']
---

<body><article id="f6b3fd13-ccb4-45f8-9fb5-1270e027e033" class="page sans"><header><h1 class="page-title">2021-04-09-텍스트분석</h1></header><div class="page-body"><blockquote id="ae070def-9cad-4749-ac1d-5938e02d1f5b" class="">요즘 세상이 참 많이 신기해졌다. 내가 쓴 글이 어떠한 감정을 내포하고 있는지도 기계가 파악하니 말이다. 이렇게 기술이 발전하기까지에는, 정말 대단한 분들의 언어 분석 연구가 있었기에 가능하다고 생각한다. 이러한 분석의 결실로써, 텍스트마이닝이 생겨나게 됐다.
오늘은 <strong>텍스트마이닝에 대한 개요</strong>를 알아보고자 한다.</blockquote><h1 id="5a472941-7f94-4c49-bd8f-731818da21d0" class="">텍스트마이닝과 NLP</h1><p id="fb0d27b9-f9b5-4858-949f-7ed267d90a89" class="">
</p><h2 id="6b90b8b2-cad8-406c-bc04-108df8e2e858" class="">NLP의 정의</h2><h3 id="a971f34f-defd-4a7c-beeb-bb6a40e33916" class="">NLP와 텍스트마이닝</h3><p id="7cbc9f8b-c88e-409d-a673-2a87f5425f47" class="">NLP란, Natural Language Processing (자연언어 처리)를 의미한다.
본질적으로 특수한 언어 분석을 수행하는 텍스트 마이닝의 구성 요소라도 볼 수 있다. <strong>인간 언어의 모호성을 해결</strong>하기 위한 방법론을 뜻한다.</p><p id="63a76b2a-3a28-46d2-b47d-f2200042ae39" class="">텍스트마이닝이란, 새로운 정보를 발견하기 위해 많은 양의 서면 자료를 조사하는 과정을 의미한다. 다양한 분석 방법을 사용하여 이를 수행하는데, 자연어 처리가 그 중 하나라고 볼 수 있다.</p><p id="cdaaa786-63f7-43bf-998d-04b2f3d27fca" class="">즉, <strong>텍스트마이닝은 텍스트에서 의미있는 정보를 추출하여 인사이트를 얻는 것</strong>이며, 이를 수행하기 위한 대표적 방법론이 NLP다. <strong>NLP는 기계가 인간의 언어를 해석</strong>하기 위한 방법이다.</p><p id="0047ba2a-3683-490d-853d-0e25d0093d43" class="">이는 놀라운 속도로 더욱 정교하게 발전하고 있다. 특히 공용어인 영어의 경우 비약한 발전을 이루고 있으며, 한글은 다양한 제약 조건(이하 설명 예정)때문에 비교적 어렵게 발전 중이다.</p><p id="54101a10-0a5c-4e32-9f7e-bef7bda388e0" class="">
</p><h2 id="76e7caaf-76ad-4813-b8c9-1efa8b362b4b" class="">텍스트 분석의 주요 영역</h2><ul id="3cf3e661-b044-4bd5-b4d6-d1fc404e9885" class="bulleted-list"><li>텍스트 분류</li></ul><ul id="cdc10816-9118-4ad8-b220-89bfd306d608" class="bulleted-list"><li>감성 분석</li></ul><ul id="742e0161-2b46-4004-bd97-a3d1e76793a8" class="bulleted-list"><li>텍스트 요약</li></ul><ul id="fac52503-cee1-4add-a2f0-7b8089967d9a" class="bulleted-list"><li>텍스트 군집화와 유사도 측정</li></ul><p id="88ce0ac1-84b9-40a7-b447-45f8c2ef6e9b" class="">
</p><h2 id="ba61851b-5378-437c-9832-fbf5f9279b63" class="">NLP 파이프라인</h2><p id="75a76855-a88e-4a21-8f43-0379c1da1ffe" class="">이처럼 다양한 영역에서 활용될 수 있는 텍스트 분석을 더욱 용이하게 하기 위해, 우리는 NLP 등의 파이프라인을 꼼꼼히 설계하고 처리해야 한다. NLP는 일반적으로 아래와 같은 순서에 맞춰져 분석이 진행된다.</p><p id="a884f945-97d5-45ec-b1bb-1d8a4e659209" class="">
</p><figure class="block-color-gray_background callout" style="white-space:pre-wrap;display:flex" id="a1826725-b851-4a41-bb08-af629373b1a5"><div style="font-size:1.5em"><span class="icon">💡</span></div><div style="width:100%">Raw Data 👉🏻Tokenization  👉🏻불용어(Stop Words)제거  👉🏻어간 추출(Stemming) or 표제어 추출(Lemmatization)  👉🏻 Nomalization(정규화) 👉🏻 Vector(벡터)화</div></figure><p id="4c06f5d9-383b-42ea-a18c-9a4c26bbe974" class="">이제 순차적으로 과정을 살펴보도록 하자. ( &#x27;Raw Data&#x27;의 경우, 말 그대로 raw data를 추출해 오는 것이므로 이 과정은 생략하겠다.)</p><p id="3ea1747d-b7f6-4020-97c3-a6118c96277b" class="">
</p><h3 id="4e62d228-0978-4779-b947-e993dda1b4f4" class=""><strong>Tokenization</strong></h3><p id="469f8440-e79d-4737-87dd-4b473a53b3ec" class="">토큰화란, <strong>의미를 가지는 가장 낮은 단위의 문자로 나누는 것</strong>을 의미한다. 이는 보통 형태소, 단어로 이뤄질 수 있다.</p><p id="cad7a267-6541-48ec-8e20-42544647e9ab" class="">올바른 토큰화를 위해, 우리는 반드시 염두에 두어야 할 두 가지 아이디어가 존재한다. 바로, <strong>대소문자 통일</strong>과 <strong>문장 부호,공백 제거</strong>가 그것이다.</p><p id="344a87dd-4de3-458a-b4a7-b81b323501a9" class="">토큰화를 하기 위해서는, 첫 번째로 <strong>1) 한 문장을 리스트화하여 형태소 단위로 나눠야 한다.</strong> 그후, 갯수를 확인하거나 top rank token을 확인해본다. (이처럼 토큰의 현 상태를 확인하고 파악하는 작업이 생각보다 중요하다.)</p><figure class="block-color-gray_background callout" style="white-space:pre-wrap;display:flex" id="3c88b6e0-5555-4e5f-a13a-6fb51983b842"><div style="font-size:1.5em"><span class="icon">💡</span></div><div style="width:100%">공백, 부호 등 제거를 위해서는 일반적으로 <strong>re 라이브러리</strong>를 활용한다.</div></figure><p id="58a90db7-34ef-4213-a058-e68ca7cd054b" class="">
</p><h3 id="824aaccc-1aa1-4982-9d77-0fc4ce195551" class=""><strong>Stop Words</strong></h3><p id="f6979a15-bee8-4e18-a867-ea5be7dfebfd" class="">그후, <strong>2) 불용어(Stop Words)를 처리</strong>한다. 대부분의 NLP라이브러리에는 불용어를 처리하기 위한 불용어 사전이 존재하기 때문에, 불용어 사전에 포함된 데이터는 일괄 토큰 삭제를 해주는 방식으로 진행하면 된다. 이때, 추가적으로 불용어를 정의해서 제거할 수도 있다.</p><p id="848d979b-7150-4437-bc86-82544c81f257" class="">
</p><h3 id="3790a374-537d-4bd8-8079-52039077db08" class=""><strong>Stemming</strong></h3><p id="135bc394-db0a-46b4-ae01-1656dfe593a2" class=""> 영어의 경우, love와 loves 같은(어미가 다르지만 의미가 같은)단어가 존재한다. 이때, love와 loves의 토큰을 별도로 나눠버리면, 컴퓨터는 이들을 다른 의미의 토큰으로 인식할 것이다. 따라서 이를 방지하기 위해<strong> 3) 어간추출(Stemming)이 필요</strong>하다.</p><p id="ebf32ec6-db04-4ce5-b338-56a9093098ce" class="">어간추출의 예시와 결과는 다음과 같다. wolf와 wolves에서, &#x27;ves&#x27;는 어미로 판단하여 제거가 된 것을 알 수 있다.</p><p id="463cc99b-50f2-4b5d-b935-0b177e025220" class="">
</p><pre id="4ec1cce2-6732-470b-9194-cb8bc3bc594d" class="code"><code>from nltk.stem import PorterStemmer

ps = PorterStemmer()
words = [&quot;wolf&quot;, &quot;wolves&quot;]

for word in words:
    print(ps.stem(word))</code></pre><pre id="f7e8854d-b180-4f0e-910f-29ce9ffdbdec" class="code"><code>wolf
wolv</code></pre><figure class="block-color-gray_background callout" style="white-space:pre-wrap;display:flex" id="940ab679-1088-4660-9027-cfd83222eaf5"><div style="font-size:1.5em"><span class="icon">💡</span></div><div style="width:100%">Spacy는 Stemming을 제공하지 않고 lemmatization만 제공한다. 따라서 Stemming을 사용할 때는 NLTK를 이용한다.</div></figure><p id="a23d28d3-a444-4e29-83ab-5a8f6efb0603" class="">
</p><h3 id="b3c4a56d-6bab-401f-8f41-00c57a3376aa" class=""><strong>Lemmatization</strong></h3><p id="8e4f7082-ba48-45b0-94b0-077a3a54c032" class="">stemming은 성능이 그리 나쁘진 않지만, 위와 같은 경우에는 또 다른 문제가 생성된다. &#x27;wolf&#x27;와 &#x27;wolv&#x27;를 다른 토큰으로 인식하게 되기 때문이다. 따라서 이럴 때, stemming보다 체계적인 Lemmatization을 활용한다. Lemmatization이란 단어들을 기본 사전형 단어 형태로 바꿔 토큰화하는 것을 뜻한다.</p><p id="5c65d48b-fd4c-493e-b036-424fd1427580" class="">
</p><h2 id="c09d86e9-8c47-48cd-95a2-b0ff81a5412b" class="">NLP를 위한 라이브러리</h2><p id="7d66d6fc-7aa7-46ab-9ded-986d7a6732a0" class="">그렇다면, NLP를 하기 위해 대표적으로 활용되고 있는 라이브러리에 대해 알아보자.</p><ul id="ca30930a-d7d3-4fe9-ba2f-ceb80d757925" class="bulleted-list"><li><strong>NLTK</strong><p id="10b2fdaf-c879-4292-ac59-1454dbe31ba8" class="">파이썬의 가장 대표적인 NLP패키지다. 방대한 데이터 세트와 서브모듈을 가지고 있으며, NLP의 거의 모든 영역을 커버하고 있다.</p></li></ul><ul id="12d24a79-692b-405c-828e-555f6d7d55d7" class="bulleted-list"><li><strong>Gensim</strong></li></ul><p id="e5f8c586-8237-4b3e-949b-be3442a31b56" class="">토픽 모델링에서 두각 나타내는 패키지다.</p><ul id="c3756ec9-18df-4957-b6d8-e99aec287027" class="bulleted-list"><li><strong>SpaCy</strong><p id="1aa7b50f-50f4-4d2c-b62c-dc7e2956e1e1" class="">뛰어난 수행 성능으로 최근 가장 주목받는 NLP 패키지다. 문서 구성요소를 다양한 구조에 나누어 저장하는 대신, 요소를 색인화하고 검색정보를 간단히 저장한다. 따라서 실제 배포단계에서 NLTK보다 유리할 수 있다고 한다. 그러나 한글 버전이 지원 안된다는 단점이 있다.</p></li></ul><p id="c7af4d96-3344-4d81-a50f-569bcbf86ea8" class="">
</p><p id="2966384c-8c13-44e3-8fc0-2c4537422127" class="">다음 포스팅에서는 벡터라이제이션 부분을 다뤄 볼 것이다. 이때 BOW, TF-IDF에 대해 기고하도록 하겠다! </p><p id="3f25c3e2-f5e1-4be9-bca5-80ead6d83b1b" class="">※ 선수지식: PCA, SVD</p><p id="ab964fa4-fdb6-432c-a37e-bfb8502bc3dd" class="">
</p><p id="2a2941d8-489f-45dc-a766-0876a172d839" class="">
</p>
